{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dd = []\n",
    "\n",
    "cascPath =  \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "inc = 0\n",
    "maxFrames = 5\n",
    "dataset = []\n",
    "\n",
    "while inc < maxFrames:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if  ret==False:\n",
    "        print(\"ERROR: No device found\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        #flags=cv2.cv.CV_HAAR_SCALE_IMAGE\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    cv2.imshow('Video', gray)   \n",
    "\n",
    "    \n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('f'):\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            resized_image = cv2.resize(cv2.imwrite(\"TEST%04i.jpg\" %inc,gray[y:y+h,x:x+w]), (100, 100))\n",
    "            dataset.append(cv2.resize(gray[y:y+h,x:x+w], (100, 100)))\n",
    "            #dataset.append(resized_image)\n",
    "            height, width = resized_image.shape[:2]      \n",
    "            print(height,width)\n",
    "            inc+=1           \n",
    "            \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', gray) \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  \n",
    "        \n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "5\n",
      "[array([[186, 186, 187, ...,  50,  49,  84],\n",
      "       [187, 188, 189, ...,  40,  51,  31],\n",
      "       [189, 190, 189, ...,  35,  60,  45],\n",
      "       ...,\n",
      "       [125, 122, 120, ..., 163, 164, 163],\n",
      "       [127, 126, 122, ..., 163, 164, 164],\n",
      "       [129, 128, 124, ..., 163, 164, 163]], dtype=uint8), array([[ 71,  71,  71, ...,  31,  30,  28],\n",
      "       [ 72,  72,  72, ...,  29,  29,  28],\n",
      "       [ 72,  71,  71, ...,  28,  28,  29],\n",
      "       ...,\n",
      "       [ 89,  86,  83, ..., 162, 161, 160],\n",
      "       [ 94,  91,  86, ..., 161, 157, 156],\n",
      "       [ 99,  95,  89, ..., 156, 155, 152]], dtype=uint8), array([[ 23,  24,  24, ...,  12,  15,  17],\n",
      "       [ 23,  23,  23, ...,  13,  15,  16],\n",
      "       [ 23,  22,  23, ...,  12,  13,  16],\n",
      "       ...,\n",
      "       [103,  99,  96, ..., 104, 104, 103],\n",
      "       [106, 102, 100, ..., 104, 104, 104],\n",
      "       [109, 105, 103, ..., 105, 104, 104]], dtype=uint8), array([[  2,   6,  23, ...,   6,   6,   6],\n",
      "       [  1,   3,   3, ...,  11,   7,   6],\n",
      "       [  2,   1,   1, ...,  11,   9,   8],\n",
      "       ...,\n",
      "       [  1,   3,   2, ..., 141, 141, 142],\n",
      "       [  1,   1,   1, ..., 134, 135, 137],\n",
      "       [  2,   2,   1, ..., 128, 129, 134]], dtype=uint8), array([[173, 172, 173, ...,   8,   8,   9],\n",
      "       [175, 175, 176, ...,   9,   9,   9],\n",
      "       [177, 176, 177, ...,  11,  10,   9],\n",
      "       ...,\n",
      "       [ 68,  69,  71, ...,  92,  89,  85],\n",
      "       [ 70,  71,  71, ...,  90,  87,  83],\n",
      "       [ 70,  71,  72, ...,  91,  87,  86]], dtype=uint8)]\n",
      "(5, 100, 100)\n",
      "[[[186 186 187 ...  50  49  84]\n",
      "  [187 188 189 ...  40  51  31]\n",
      "  [189 190 189 ...  35  60  45]\n",
      "  ...\n",
      "  [125 122 120 ... 163 164 163]\n",
      "  [127 126 122 ... 163 164 164]\n",
      "  [129 128 124 ... 163 164 163]]\n",
      "\n",
      " [[ 71  71  71 ...  31  30  28]\n",
      "  [ 72  72  72 ...  29  29  28]\n",
      "  [ 72  71  71 ...  28  28  29]\n",
      "  ...\n",
      "  [ 89  86  83 ... 162 161 160]\n",
      "  [ 94  91  86 ... 161 157 156]\n",
      "  [ 99  95  89 ... 156 155 152]]\n",
      "\n",
      " [[ 23  24  24 ...  12  15  17]\n",
      "  [ 23  23  23 ...  13  15  16]\n",
      "  [ 23  22  23 ...  12  13  16]\n",
      "  ...\n",
      "  [103  99  96 ... 104 104 103]\n",
      "  [106 102 100 ... 104 104 104]\n",
      "  [109 105 103 ... 105 104 104]]\n",
      "\n",
      " [[  2   6  23 ...   6   6   6]\n",
      "  [  1   3   3 ...  11   7   6]\n",
      "  [  2   1   1 ...  11   9   8]\n",
      "  ...\n",
      "  [  1   3   2 ... 141 141 142]\n",
      "  [  1   1   1 ... 134 135 137]\n",
      "  [  2   2   1 ... 128 129 134]]\n",
      "\n",
      " [[173 172 173 ...   8   8   9]\n",
      "  [175 175 176 ...   9   9   9]\n",
      "  [177 176 177 ...  11  10   9]\n",
      "  ...\n",
      "  [ 68  69  71 ...  92  89  85]\n",
      "  [ 70  71  71 ...  90  87  83]\n",
      "  [ 70  71  72 ...  91  87  86]]]\n",
      "(5, 10000)\n",
      "[[186 186 187 ... 163 164 163]\n",
      " [ 71  71  71 ... 156 155 152]\n",
      " [ 23  24  24 ... 105 104 104]\n",
      " [  2   6  23 ... 128 129 134]\n",
      " [173 172 173 ...  91  87  86]]\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "print(len(dataset))\n",
    "print(dataset)\n",
    "\n",
    "dd = np.asarray(dataset)\n",
    "print(dd.shape)\n",
    "print(dd)\n",
    "\n",
    "dd=np.reshape(dd,(5,10000))\n",
    "print(dd.shape)\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YO\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "etiq = {0:'YO',1:'Jona',2:'Stef',3:'Harry'}\n",
    "print(etiq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dela = np.array(pd.read_csv('delaGala.csv',sep=',',header=None))\n",
    "jona = np.array(pd.read_csv('jonatan.csv', sep=',',header=None))\n",
    "stef = np.array(pd.read_csv('stefanie.csv',sep=',',header=None))\n",
    "hary = np.array(pd.read_csv('harry.csv',   sep=',',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000)\n",
      "(100, 10000)\n",
      "(100, 10000)\n",
      "(100, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[107,  93,  82, ...,   1,   0,   0],\n",
       "       [108,  82,  85, ...,   0,   0,   0],\n",
       "       [144, 137, 136, ...,   9,  12,  15],\n",
       "       ...,\n",
       "       [112,  98,  89, ...,   5,   4,   2],\n",
       "       [150, 144, 147, ...,   2,   2,   2],\n",
       "       [135, 115, 117, ...,   3,   4,   3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stef=stef[:-4, :]\n",
    "print(dela.shape)\n",
    "print(jona.shape)\n",
    "print(stef.shape)\n",
    "print(hary.shape)\n",
    "stef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10000)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((dela,jona,stef,hary), axis=0)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(400, 4)\n"
     ]
    }
   ],
   "source": [
    "y_dela = []\n",
    "y_jona = []\n",
    "y_stef = []\n",
    "y_hary = []\n",
    "\n",
    "for i in range(0,dela.shape[0]):\n",
    "   y_dela.append([1,0,0,0])\n",
    "\n",
    "for i in range(0,jona.shape[0]):\n",
    "   y_jona.append([0,1,0,0])\n",
    "\n",
    "for i in range(0,stef.shape[0]):\n",
    "   y_stef.append([0,0,1,0])\n",
    "\n",
    "for i in range(0,hary.shape[0]):\n",
    "   y_hary.append([0,0,0,1])\n",
    "\n",
    "print(len(y_stef))\n",
    "\n",
    "y_dela = np.array(y_dela)\n",
    "y_jona = np.array(y_jona)\n",
    "y_stef = np.array(y_stef)\n",
    "y_hary = np.array(y_hary)\n",
    "\n",
    "y = np.concatenate((y_dela,y_jona,y_stef,y_hary), axis=0)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.datasets import make_classification\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#clf = RandomForestClassifier(n_estimators=1, max_depth=1,random_state=0)\n",
    "#clf.fit(X_train, y_train)\n",
    "#print(clf.feature_importances_)\n",
    "\n",
    "#prediction = clf.predict(dd)\n",
    "#print(accuracy_score(y_test, yPred))\n",
    "#print(prediction)\n",
    "#predi = np.argmax(prediction, axis=1)\n",
    "#print(predi)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "#scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 10          # filtros 10 x 10 pixels.\n",
    "num_filters1 = 20         e\n",
    "#scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "#scores \n",
    "\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 10         \n",
    "num_filters2 = 40         \n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 100   \n",
    "img_size_flat = img_size*img_size\n",
    "img_shape = (img_size,img_size)\n",
    "num_classes = 4\n",
    "num_channels = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # capa anterior\n",
    "                   num_input_channels, \n",
    "                   filter_size,        \n",
    "                   num_filters,        \n",
    "                   use_pooling=True):  # 2x2 max-pooling.\n",
    "\n",
    "    # Shape de los filtros-pesos para la convolution.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # filtros con shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # un bias por cada filtro\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    # Strides\n",
    "    # siempre 1 para el primero -> image-number \n",
    "    # siempre 1 para el ultimo -> the input-channel.\n",
    "    # los del centro hacen q se mueva cada 1 pixel\n",
    "    # padding -> size de la salida la misma\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    # achicar imagenes\n",
    "    if use_pooling:\n",
    "        # 2x2 max-pooling\n",
    "        # sacar el mayor valor del 2x2\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # max(x, 0) por cada pixel \n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # capa anterior\n",
    "                 num_inputs,     \n",
    "                 num_outputs,    \n",
    "                 use_relu=True): \n",
    "\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 50, 50, 20) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 25, 25, 40) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 25000) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat     #25*25*40 layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully-Connected Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully-Connected Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)\n",
    "\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-fa95eb97bf8c>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,   ##funcion de costo\n",
    "                                                        labels=y_true)\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "train_batch_size = 64\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Batches de entrenamiento\n",
    "        x_batch = X_train\n",
    "        y_true_batch = y_train\n",
    "\n",
    "        # Se ponen en un dict para poder ponerlos en los placeholders\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        if i % 1 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred,cls_true):\n",
    "    # cls_pred : array de las predicccions en el testset\n",
    "\n",
    "    # cls_true : y verdaderas\n",
    "    \n",
    "    # Sklearn.\n",
    "    cm = confusion_matrix(cls_true, cls_pred)\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.matshow(cm)\n",
    "\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy():\n",
    "\n",
    "    num_test = X_test.shape[0]\n",
    "    \n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "    \n",
    "    cls_true = []\n",
    "    \n",
    "    for i in range(0,y_test.shape[0]):\n",
    "        cls_true.append(np.argmax(y_test[i]))\n",
    "        \n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        images = X_test[i:j, :]\n",
    "        labels = y_test[i:j, :]\n",
    "\n",
    "        feed_dict = {x: images, y_true: labels}\n",
    "\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        i = j\n",
    "\n",
    "\n",
    "    # si son correctas\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    plot_confusion_matrix(cls_pred,cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  26.5%\n",
      "Optimization Iteration:      2, Training Accuracy:  43.3%\n",
      "Optimization Iteration:      3, Training Accuracy:  43.3%\n",
      "Optimization Iteration:      4, Training Accuracy:  69.8%\n",
      "Optimization Iteration:      5, Training Accuracy:  65.3%\n",
      "Optimization Iteration:      6, Training Accuracy:  67.5%\n",
      "Optimization Iteration:      7, Training Accuracy:  84.7%\n",
      "Optimization Iteration:      8, Training Accuracy:  87.3%\n",
      "Optimization Iteration:      9, Training Accuracy:  82.8%\n",
      "Optimization Iteration:     10, Training Accuracy:  82.8%\n",
      "Optimization Iteration:     11, Training Accuracy:  81.7%\n",
      "Optimization Iteration:     12, Training Accuracy:  86.9%\n",
      "Optimization Iteration:     13, Training Accuracy:  92.9%\n",
      "Optimization Iteration:     14, Training Accuracy:  93.7%\n",
      "Optimization Iteration:     15, Training Accuracy:  94.0%\n",
      "Time usage: 0:09:22\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 97.7% (129 / 132)\n",
      "Confusion Matrix:\n",
      "[[38  0  0  1]\n",
      " [ 0 30  0  0]\n",
      " [ 0  0 30  1]\n",
      " [ 1  0  0 31]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD3CAYAAAD/jPo0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[186 186 187 ... 163 164 163]\n",
      " [ 71  71  71 ... 156 155 152]\n",
      " [ 23  24  24 ... 105 104 104]\n",
      " [  2   6  23 ... 128 129 134]\n",
      " [173 172 173 ...  91  87  86]]\n",
      "[array([[1.0000000e+00, 2.7841025e-23, 0.0000000e+00, 6.1833000e-18],\n",
      "       [9.9999952e-01, 0.0000000e+00, 4.4811542e-31, 4.5800292e-07],\n",
      "       [1.0000000e+00, 5.2133318e-36, 0.0000000e+00, 9.7351502e-12],\n",
      "       [9.9999928e-01, 0.0000000e+00, 7.0730425e-07, 1.9626654e-24],\n",
      "       [3.2624229e-34, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00]],\n",
      "      dtype=float32)]\n",
      "(5, 4)\n",
      "[0 0 0 0 3]\n",
      "YO\n",
      "YO\n",
      "YO\n",
      "YO\n",
      "Harry\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {x : dd}\n",
    "predi = session.run([y_pred], feed_dict)\n",
    "print(predi)\n",
    "\n",
    "predi = np.asarray(np.hstack(predi))\n",
    "print(predi.shape)\n",
    "\n",
    "predi = np.argmax(predi,axis=1)\n",
    "print(predi)\n",
    "\n",
    "for i in range(5):\n",
    "    print(etiq[predi[i]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
